\section{Results \& Discussion}

Interestingly, we noticed that our internal deviations in the BLEU score are not as great as on the official test set.

\begin{table}[H]
    \centering
    \begin{tabular}{llll}
    \hline\textbf{Model\#}    & \textbf{Data} & \textbf{Train BLEU}   & \textbf{Test BLEU} \\\hline   %\\\hline %\rowcolor{gray!50}
    1                   & SwissText     & 0.23                  & 0.0004                \\%\hline %DeepSpeech (Trained from scratch)
    2                   & ArchiMob      & 0.27                  & \textbf{0.17}         \\%\hline %DeepSpeech (Pre-trained)
    3                   & ArchiMob      & 0.24                  & 0.07                  \\%\hline %DeepSpeech + Opus-MT-DE-EN (Pre-trained)
    4                   & ArchiMob      & 0.24                  & 0.07                  \\%\hline %DeepSpeech + Opus-MT-DE-EN (Pre-trained)
    5                   & ArchiMob      & 0.24                  & 0.07                  \\%\hline %DeepSpeech + Opus-MT-DE-EN (Pre-trained)
    \hline
    \end{tabular}
    \caption{\label{font-table} Font guide. }
\end{table}

%\begin{table}[b]
%    \centering
%    \begin{tabular}{lllll}
%    %\begin{tabularx}{\linewidth}{|Y|Z|Y|s|s|}
%        \hline
%        \textbf{Model#} & \textbf{Data} & \textbf{Additional information}           & \textbf{Train BLEU}   & \textbf{Test BLEU}    \\\hline %\rowcolor{gray!50}
%        1               & SwissText     & -                                         & 0.23                  & 0.0004                \\\hline %DeepSpeech (Trained from scratch)
%        2               & ArchiMob      & Fine-tuned on latest German DeepSpeech    & 0.27                  & \textbf{0.17}         \\\hline %DeepSpeech (Pre-trained)
%        3               & ArchiMob      & Additional sequence to sequence model     & 0.24                  & 0.07                  \\\hline %DeepSpeech + Opus-MT-DE-EN (Pre-trained)
%    \end{tabular}
% %   \end{tabularx}
%    \caption{Results}
%    \label{tab:Results}
%\end{table}
