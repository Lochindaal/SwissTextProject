\section{Literature review}
The shared task of translating spoken Swiss German into standard written German was already presented by the \gls{stc} in 2020. The only difference between the tasks is that this year's task provides
more data, while last year's task was specifically about low-resource languages. While the current 2021 task is about reaching the highest BLEU score, last year's submissions were ranked based on the
least \gls{wer}. \citet{buechi2020} achieved the best \gls{wer} of 40.29\%. The authors used a CNN acoustic model named Jasper. They used additional Standard German data and fine-tuned on the official
data set. They used different augmentation techniques and a language model. \citet{Kew2020} achieved the second-best \gls{wer} of 45.45\%. They used a DNN-HMM time-delay neural model including a specifically created pronunciation lexicon.   \\
\citet{Agarwal2020LTLUDEAL} used an end-to-end model called DeepSpeech and achieved an \gls{wer} of 58.93\%. This is the model we decided to use as well. It is publicly available on GitHub and can easily be fine-tuned or used for transfer learning \cite{pluss2020}.
